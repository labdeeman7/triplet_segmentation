{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from pycocotools import mask as coco_mask\n",
    "\n",
    "from utils.general.dataset_variables import TripletSegmentationVariables \n",
    "\n",
    "TRIPLET_DICT = TripletSegmentationVariables.categories['triplet']\n",
    "# multitask instrument verb and target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For triplet direct not multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_file_path = '../results/mask2former_direct_triplet_prediction/mask2former_direct_triplet_prediction_best_coco_bbox_mAP_iter_60000.pkl'\n",
    "# output_json_path  = '../results/mask2former_direct_triplet_prediction/predicted_logits.json'\n",
    "\n",
    "# pickle_file_path = '../results/full_results_mask2former_multihead/mask2former_one_stage_multihead_full_best_coco_segm_mAP_iter_24500.pkl'\n",
    "# output_json_path  = '../results/full_results_mask2former_multihead/predicted_logits.json'\n",
    "\n",
    "pickle_file_path = '../results/triplet_direct_v2/mask2former_test_results.pkl'\n",
    "output_json_path  = '../results/triplet_direct_v2/predicted_logits.json'\n",
    "\n",
    "\n",
    "# output_mask_dir = '../../datasets/my_triplet_seg_datasets/triplet_segmentation_dataset_v2_second_stage/test_soft_labels/predicted_instance_masks'\n",
    "\n",
    "# temperature = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_file_path, 'rb') as file:\n",
    "        # Load the object from the file\n",
    "        mmdet_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mmdet_results[0]['pred_instances']['logits'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved softmax JSON to: ../results/triplet_direct_v2/predicted_logits.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize output dictionary\n",
    "final_json = {}\n",
    "\n",
    "for result  in mmdet_results:\n",
    "    img_filename = os.path.basename(result ['img_path'])\n",
    "    img_id = os.path.splitext(img_filename)[0]\n",
    "\n",
    "    pred_instances = result['pred_instances']\n",
    "    masks = pred_instances['masks']\n",
    "    scores = pred_instances['scores']\n",
    "    logits = pred_instances['logits']\n",
    "    labels = pred_instances['labels']\n",
    "    \n",
    "    # Convert to numpy if needed\n",
    "    if isinstance(masks, torch.Tensor):\n",
    "        masks = masks.cpu().numpy()\n",
    "    if isinstance(logits, torch.Tensor):\n",
    "        logits = logits.cpu().numpy()\n",
    "    if isinstance(scores, torch.Tensor):\n",
    "        scores = scores.cpu().numpy()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "    image_instances = []\n",
    "    \n",
    "    if isinstance(masks, torch.Tensor):\n",
    "        masks = masks.cpu().numpy()\n",
    "    \n",
    "    label_id_instance_id = {i: 0 for i in range(100)}\n",
    "\n",
    "    for i, (score, logit, label) in enumerate(zip(scores, logits, labels)):\n",
    "        if score < 0.5:\n",
    "            continue\n",
    "        \n",
    "        label_id_instance_id[label] += 1\n",
    "        \n",
    "        rle = masks[i]\n",
    "        instance_mask = coco_mask.decode(rle).astype(np.uint8) * 255  # Binary mask\n",
    "        \n",
    "        # Remove snare class from logits\n",
    "        softmax = torch.nn.functional.softmax(torch.tensor(logit), dim=0).numpy()\n",
    "        predicted_class_name = TRIPLET_DICT[str(label + 1)]\n",
    "\n",
    "        \n",
    "        # Save binary mask\n",
    "        mask_filename = f\"{img_id}_{predicted_class_name}_instance_{label_id_instance_id[i]}.png\"\n",
    "        # mask_path = os.path.join(output_mask_dir, mask_filename)\n",
    "        # Image.fromarray(instance_mask).save(mask_path)\n",
    "        \n",
    "        image_instances.append({\n",
    "            \"instance_id\": i,\n",
    "            \"predicted_class_name\": predicted_class_name,\n",
    "            \"softmax\": softmax.tolist(),\n",
    "            \"mask_path\": mask_filename\n",
    "        })\n",
    "        \n",
    "    # Save None if no valid detections\n",
    "    final_json[img_id] = image_instances if image_instances else None\n",
    "        \n",
    "\n",
    "\n",
    "# Save\n",
    "with open(output_json_path, 'w') as f:\n",
    "    json.dump(final_json, f, indent=4)\n",
    "\n",
    "print(f\"✅ Saved softmax JSON to: {output_json_path}\")\n",
    "# print(f\"✅ Masks saved to: {output_mask_dir}\")            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_file_path = '../results/mask2former_direct_triplet_prediction/mask2former_direct_triplet_prediction_best_coco_bbox_mAP_iter_60000.pkl'\n",
    "# output_json_path  = '../results/mask2former_direct_triplet_prediction/predicted_logits.json'\n",
    "\n",
    "# pickle_file_path = '../results/full_results_mask2former_multihead/mask2former_one_stage_multihead_full_best_coco_segm_mAP_iter_24500.pkl'\n",
    "# output_json_path  = '../results/full_results_mask2former_multihead/predicted_logits.json'\n",
    "\n",
    "# pickle_file_path = '../results/triplet_direct_v2/mask2former_test_results.pkl'\n",
    "# output_json_path  = '../results/triplet_direct_v2/predicted_logits.json'\n",
    "\n",
    "pickle_file_path = '../results/multiple_heads_v2/mask2former_test_results.pkl'\n",
    "output_json_path  = '../results/multiple_heads_v2/predicted_logits.json'\n",
    "triplet_map_path=\"../utils/general/maps.txt\"\n",
    "\n",
    "\n",
    "\n",
    "# output_mask_dir = '../../datasets/my_triplet_seg_datasets/triplet_segmentation_dataset_v2_second_stage/test_soft_labels/predicted_instance_masks'\n",
    "\n",
    "# temperature = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_file_path, 'rb') as file:\n",
    "        # Load the object from the file\n",
    "        mmdet_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target_labels', 'target_scores', 'bboxes', 'logits', 'labels', 'verb_scores', 'scores', 'masks', 'verb_labels', 'target_logits', 'verb_logits'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(mmdet_results[0]['pred_instances']['logits'][0])\n",
    "\n",
    "mmdet_results[0]['pred_instances'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmdet_results[0]['pred_instances']['scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_valid_triplets(path=\"maps.txt\"):\n",
    "    triplets = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip().startswith('# IVT'):\n",
    "                continue  # skip header\n",
    "            ivt, i, v, t, _, _ = line.strip().split(',')\n",
    "            triplets.append((int(ivt), int(i), int(v), int(t)))\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = np.array(x)\n",
    "    e_x = np.exp(x - np.max(x))  # for numerical stability\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def generate_softmax_score_for_detected_objects_from_multitask_instrument_verb_and_target_logit(logits_instrument, logits_verb, logits_target, triplet_map):   \n",
    "    \n",
    "    instrument_logits = np.array(logits_instrument) \n",
    "    verb_logits = np.array(logits_verb)\n",
    "    target_logits =  np.array(logits_target)\n",
    "    \n",
    "    instrument_probs = softmax(instrument_logits)\n",
    "    verb_probs = softmax(verb_logits)\n",
    "    target_probs = softmax(target_logits)\n",
    "    \n",
    "   \n",
    "    triplet_softmax = np.zeros(len(triplet_map))\n",
    "    \n",
    "    for idx, (ivt, i, v, t) in enumerate(triplet_map):\n",
    "        triplet_softmax[ivt] = instrument_probs[i] * verb_probs[v] * target_probs[t]\n",
    "    \n",
    "    triplet_softmax = triplet_softmax / triplet_softmax.sum()      \n",
    "\n",
    "    predicted_triplet_index = int(np.argmax(triplet_softmax)) + 1  # if triplet_dict is 1-based\n",
    "    predicted_triplet_name = TRIPLET_DICT[str(predicted_triplet_index)]\n",
    "    \n",
    "    predicted_class_name = predicted_triplet_name.split(',')[0]\n",
    "\n",
    "    return triplet_softmax, predicted_triplet_name, predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize output dictionary\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "final_json = {}\n",
    "\n",
    "def generate_predicted_logits_multitask(mmdet_results, output_json_path):\n",
    "\n",
    "    for result  in mmdet_results:\n",
    "        img_filename = os.path.basename(result ['img_path'])\n",
    "        img_id = os.path.splitext(img_filename)[0]\n",
    "\n",
    "        pred_instances = result['pred_instances']\n",
    "        masks = pred_instances['masks']\n",
    "        \n",
    "        instrument_scores = pred_instances['scores']\n",
    "        instrument_logits = pred_instances['logits']\n",
    "        instrument_labels = pred_instances['labels']\n",
    "        \n",
    "        verb_scores = pred_instances['verb_scores']\n",
    "        verb_logits = pred_instances['verb_logits']\n",
    "        verb_labels = pred_instances['verb_labels']\n",
    "        \n",
    "        \n",
    "        target_scores = pred_instances['target_scores']\n",
    "        target_logits = pred_instances['target_logits']\n",
    "        target_labels = pred_instances['target_labels']\n",
    "        \n",
    "        # Convert to numpy if needed\n",
    "        if isinstance(masks, torch.Tensor):\n",
    "            masks = masks.cpu().numpy()\n",
    "            \n",
    "        if isinstance(instrument_logits, torch.Tensor):\n",
    "            instrument_logits = instrument_logits.cpu().numpy()\n",
    "        if isinstance(instrument_scores, torch.Tensor):\n",
    "            instrument_scores = instrument_scores.cpu().numpy()\n",
    "        if isinstance(instrument_labels, torch.Tensor):\n",
    "            instrument_labels = instrument_labels.cpu().numpy()\n",
    "            \n",
    "        if isinstance(verb_logits, torch.Tensor):\n",
    "            verb_logits = verb_logits.cpu().numpy()\n",
    "        if isinstance(verb_scores, torch.Tensor):\n",
    "            verb_scores = verb_scores.cpu().numpy()\n",
    "        if isinstance(verb_labels, torch.Tensor):\n",
    "            verb_labels = verb_labels.cpu().numpy()  \n",
    "            \n",
    "        if isinstance(target_logits, torch.Tensor):\n",
    "            target_logits = target_logits.cpu().numpy()\n",
    "        if isinstance(target_scores, torch.Tensor):\n",
    "            target_scores = target_scores.cpu().numpy()\n",
    "        if isinstance(target_labels, torch.Tensor):\n",
    "            target_labels = target_labels.cpu().numpy()        \n",
    "\n",
    "        image_instances = []\n",
    "        \n",
    "        if isinstance(masks, torch.Tensor):\n",
    "            masks = masks.cpu().numpy()\n",
    "        \n",
    "        label_name_instance_id = defaultdict(int)\n",
    "\n",
    "        for i, (instrument_score, verb_score, target_score,\n",
    "                instrument_logit, verb_logit, target_logit,\n",
    "                instrument_label, verb_label, target_label) in enumerate(zip(instrument_scores, verb_scores, target_scores,\n",
    "                                                    instrument_logits, verb_logits, target_logits,\n",
    "                                                    instrument_labels, verb_labels, target_labels)):\n",
    "            if instrument_score < 0.5:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            rle = masks[i]\n",
    "            # instance_mask = coco_mask.decode(rle).astype(np.uint8) * 255  # Binary mask\n",
    "            \n",
    "            # Remove snare class from logits\n",
    "            # softmax = torch.nn.functional.softmax(torch.tensor(logit), dim=0).numpy()\n",
    "            # predicted_class_name = TRIPLET_DICT[str(label + 1)]\n",
    "            \n",
    "            triplet_map = load_valid_triplets(path=triplet_map_path)\n",
    "            softmax, predicted_triplet_name, predicted_class_name = generate_softmax_score_for_detected_objects_from_multitask_instrument_verb_and_target_logit(instrument_logit, verb_logit, target_logit,  triplet_map)\n",
    "\n",
    "            # print(softmax)\n",
    "            # print(predicted_triplet_name)\n",
    "            # print(predicted_class_name)\n",
    "            \n",
    "            label_name_instance_id[predicted_triplet_name] += 1\n",
    "            \n",
    "            # Save binary mask\n",
    "            mask_filename = f\"{img_id}_{predicted_class_name}_instance_{label_name_instance_id[predicted_triplet_name] }.png\"\n",
    "            # mask_path = os.path.join(output_mask_dir, mask_filename)\n",
    "            # Image.fromarray(instance_mask).save(mask_path)\n",
    "            \n",
    "            \n",
    "            image_instances.append({\n",
    "                \"instance_id\": i,\n",
    "                \"predicted_class_name\": predicted_triplet_name,\n",
    "                \"softmax\": softmax.tolist(),\n",
    "                \"mask_path\": mask_filename\n",
    "            })\n",
    "            \n",
    "        # Save None if no valid detections\n",
    "        final_json[img_id] = image_instances if image_instances else None\n",
    "            \n",
    "\n",
    "\n",
    "    # Save\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(final_json, f, indent=4)\n",
    "\n",
    "    print(f\"✅ Saved softmax JSON to: {output_json_path}\")\n",
    "    # print(f\"✅ Masks saved to: {output_mask_dir}\")            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved softmax JSON to: ../results/multiple_heads_v2/predicted_logits.json\n"
     ]
    }
   ],
   "source": [
    "generate_predicted_logits_multitask(mmdet_results, output_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tripletsegmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

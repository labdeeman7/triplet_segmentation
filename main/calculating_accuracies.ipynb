{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to calculate accuracies\n",
    "\n",
    "FOr the three task model and the rendezvous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def load_ground_truth_components(labelme_path, mode=\"triplet\"):\n",
    "    with open(labelme_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    gt_items = set()\n",
    "    for shape in data.get(\"shapes\", []):\n",
    "        instrument = shape.get(\"label\")\n",
    "        verb = shape.get(\"verb\")\n",
    "        target = shape.get(\"target\")\n",
    "\n",
    "        if mode == \"instrument\":\n",
    "            if instrument: gt_items.add(instrument)\n",
    "        elif mode == \"verb\":\n",
    "            if verb: gt_items.add(verb)\n",
    "        elif mode == \"target\":\n",
    "            if target: gt_items.add(target)\n",
    "        elif mode == \"triplet\":\n",
    "            if instrument and verb and target:\n",
    "                gt_items.add(f\"{instrument},{verb},{target}\")\n",
    "    \n",
    "    return gt_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def load_ground_truth_components(labelme_path, mode=\"triplet\"):\n",
    "    with open(labelme_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    gt_items = set()\n",
    "    for shape in data.get(\"shapes\", []):\n",
    "        instrument = shape.get(\"label\")\n",
    "        verb = shape.get(\"verb\")\n",
    "        target = shape.get(\"target\")\n",
    "\n",
    "        if mode == \"instrument\":\n",
    "            if instrument: gt_items.add(instrument)\n",
    "        elif mode == \"verb\":\n",
    "            if verb: gt_items.add(verb)\n",
    "        elif mode == \"target\":\n",
    "            if target: gt_items.add(target)\n",
    "        elif mode == \"triplet\":\n",
    "            if instrument and verb and target:\n",
    "                gt_items.add(f\"{instrument},{verb},{target}\")\n",
    "    \n",
    "    return gt_items\n",
    "\n",
    "\n",
    "def evaluate_triplet_predictions(prediction_json_path, labelme_dir, mode=\"triplet\"):\n",
    "    \"\"\"\n",
    "    Evaluates prediction performance across images.\n",
    "    \n",
    "    Args:\n",
    "        prediction_json_path: Path to prediction file.\n",
    "        labelme_dir: Directory with LabelMe-style ground truth JSONs.\n",
    "        mode: 'instrument', 'verb', 'target', or 'triplet'.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with accuracy, precision, recall, f1, tp, fp, fn, total_images, correct_images\n",
    "    \"\"\"\n",
    "    with open(prediction_json_path, 'r') as f:\n",
    "        predictions = json.load(f)\n",
    "\n",
    "    total_images = 0\n",
    "    correct_images = 0\n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "\n",
    "    for image_name, pred_data in predictions.items():\n",
    "        labelme_path = os.path.join(labelme_dir, f\"t50_{image_name}.json\")\n",
    "        if not os.path.exists(labelme_path):\n",
    "            print(f\"Skipping {image_name} (no labelme file found)\")\n",
    "            continue\n",
    "\n",
    "        gt_items = load_ground_truth_components(labelme_path, mode=mode)\n",
    "\n",
    "        # Extract prediction items\n",
    "        pred_triplets = pred_data[\"triplet_name\"]\n",
    "        if mode == \"instrument\":\n",
    "            pred_items = {t.split(\",\")[0] for t in pred_triplets if \",\" in t}\n",
    "        elif mode == \"verb\":\n",
    "            pred_items = {t.split(\",\")[1] for t in pred_triplets if \",\" in t}\n",
    "        elif mode == \"target\":\n",
    "            pred_items = {t.split(\",\")[2] for t in pred_triplets if \",\" in t}\n",
    "        elif mode == \"triplet\":\n",
    "            pred_items = set(pred_triplets)\n",
    "\n",
    "        tp = len(gt_items & pred_items)\n",
    "        fp = len(pred_items - gt_items)\n",
    "        fn = len(gt_items - pred_items)\n",
    "\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "\n",
    "        total_images += 1\n",
    "        if tp > 0:\n",
    "            correct_images += 1\n",
    "\n",
    "    # Image-level accuracy\n",
    "    accuracy = total_tp / (total_tp + total_fp + total_fn)  if total_images > 0 else 0.0\n",
    "\n",
    "    # Precision, recall, f1\n",
    "    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    print(f\"\\n{mode.title()} Evaluation:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f} \")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  TP: {total_tp}, FP: {total_fp}, FN: {total_fn}\")\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are there so many false negatives in my model?? Makes no sense really. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dir =  '../../datasets/my_triplet_seg_datasets/triplet_segmentation_dataset_v2_second_stage/test/ann_dir/'\n",
    "rendezvous_json_path = '../resnet_model/work_dirs/rendezvous_cholectriplet_seg/updated_rendezvous_results.json'\n",
    "my_direct_model_json_path = '../results/mask2former_direct_triplet_prediction/results_triplet_softmax_scores.json'\n",
    "my_model_json_path = '../resnet_model/work_dirs/threetask_resnet_fpn_parallel_decoders/results_triplet_softmax_scores.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instrument Evaluation:\n",
      "  Accuracy:  0.5669 \n",
      "  Precision: 0.8829\n",
      "  Recall:    0.6130\n",
      "  F1 Score:  0.7236\n",
      "  TP: 3512, FP: 466, FN: 2217\n",
      "\n",
      "Verb Evaluation:\n",
      "  Accuracy:  0.5078 \n",
      "  Precision: 0.8089\n",
      "  Recall:    0.5770\n",
      "  F1 Score:  0.6736\n",
      "  TP: 3281, FP: 775, FN: 2405\n",
      "\n",
      "Target Evaluation:\n",
      "  Accuracy:  0.4126 \n",
      "  Precision: 0.6563\n",
      "  Recall:    0.5263\n",
      "  F1 Score:  0.5842\n",
      "  TP: 2641, FP: 1383, FN: 2377\n",
      "\n",
      "Triplet Evaluation:\n",
      "  Accuracy:  0.3323 \n",
      "  Precision: 0.5688\n",
      "  Recall:    0.4442\n",
      "  F1 Score:  0.4989\n",
      "  TP: 2545, FP: 1929, FN: 3184\n"
     ]
    }
   ],
   "source": [
    "evaluate_triplet_predictions(rendezvous_json_path, ground_truth_dir, mode=\"instrument\")\n",
    "evaluate_triplet_predictions(rendezvous_json_path, ground_truth_dir, mode=\"verb\")\n",
    "evaluate_triplet_predictions(rendezvous_json_path, ground_truth_dir, mode=\"target\")\n",
    "evaluate_triplet_predictions(rendezvous_json_path, ground_truth_dir, mode=\"triplet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instrument Evaluation:\n",
      "  Accuracy:  0.9107 \n",
      "  Precision: 0.9637\n",
      "  Recall:    0.9430\n",
      "  F1 Score:  0.9533\n",
      "  TP: 5363, FP: 202, FN: 324\n",
      "\n",
      "Verb Evaluation:\n",
      "  Accuracy:  0.7380 \n",
      "  Precision: 0.8551\n",
      "  Recall:    0.8436\n",
      "  F1 Score:  0.8493\n",
      "  TP: 4761, FP: 807, FN: 883\n",
      "\n",
      "Target Evaluation:\n",
      "  Accuracy:  0.4704 \n",
      "  Precision: 0.6413\n",
      "  Recall:    0.6383\n",
      "  F1 Score:  0.6398\n",
      "  TP: 3177, FP: 1777, FN: 1800\n",
      "\n",
      "Triplet Evaluation:\n",
      "  Accuracy:  0.4103 \n",
      "  Precision: 0.5857\n",
      "  Recall:    0.5780\n",
      "  F1 Score:  0.5818\n",
      "  TP: 3287, FP: 2325, FN: 2400\n"
     ]
    }
   ],
   "source": [
    "evaluate_triplet_predictions(my_model_json_path, ground_truth_dir, mode=\"instrument\")\n",
    "evaluate_triplet_predictions(my_model_json_path, ground_truth_dir, mode=\"verb\")\n",
    "evaluate_triplet_predictions(my_model_json_path, ground_truth_dir, mode=\"target\")\n",
    "evaluate_triplet_predictions(my_model_json_path, ground_truth_dir, mode=\"triplet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instrument Evaluation:\n",
      "  Accuracy:  0.8800 \n",
      "  Precision: 0.9548\n",
      "  Recall:    0.9183\n",
      "  F1 Score:  0.9362\n",
      "  TP: 5066, FP: 240, FN: 451\n",
      "\n",
      "Verb Evaluation:\n",
      "  Accuracy:  0.7212 \n",
      "  Precision: 0.8350\n",
      "  Recall:    0.8411\n",
      "  F1 Score:  0.8380\n",
      "  TP: 4604, FP: 910, FN: 870\n",
      "\n",
      "Target Evaluation:\n",
      "  Accuracy:  0.5173 \n",
      "  Precision: 0.6626\n",
      "  Recall:    0.7023\n",
      "  F1 Score:  0.6819\n",
      "  TP: 3380, FP: 1721, FN: 1433\n",
      "\n",
      "Triplet Evaluation:\n",
      "  Accuracy:  0.4605 \n",
      "  Precision: 0.6083\n",
      "  Recall:    0.6547\n",
      "  F1 Score:  0.6306\n",
      "  TP: 3612, FP: 2326, FN: 1905\n"
     ]
    }
   ],
   "source": [
    "evaluate_triplet_predictions(my_direct_model_json_path, ground_truth_dir, mode=\"instrument\")\n",
    "evaluate_triplet_predictions(my_direct_model_json_path, ground_truth_dir, mode=\"verb\")\n",
    "evaluate_triplet_predictions(my_direct_model_json_path, ground_truth_dir, mode=\"target\")\n",
    "evaluate_triplet_predictions(my_direct_model_json_path, ground_truth_dir, mode=\"triplet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tripletsegmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

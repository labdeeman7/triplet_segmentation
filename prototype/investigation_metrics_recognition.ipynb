{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to count all the frequencies of all the triplets in each of the video sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs: 55\n",
      "0.2890225939592308\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "results_cholecT50_chal = [np.nan, np.nan, np.nan, np.nan, 1.42380420e-01, 5.12557663e-04, np.nan, 3.32626728e-01,\n",
    "          1.94041245e-02, 4.41499286e-03, 1.51810978e-02, 1.05866348e-01, 7.66676512e-01, \n",
    "          3.34643930e-01, np.nan, np.nan, np.nan, 3.49844877e-01, 2.36705437e-01, 6.40751279e-01,\n",
    "          np.nan, np.nan, 6.16255123e-01, 3.82526038e-01, np.nan, np.nan, np.nan, np.nan, np.nan, \n",
    "          9.38378809e-01, np.nan, 6.81760326e-01, np.nan, 2.39063315e-01, 6.76337083e-01, np.nan, \n",
    "          1.46892996e-01, np.nan, np.nan, np.nan, 2.24427652e-02, np.nan, np.nan, np.nan, np.nan, \n",
    "          np.nan, 5.29207639e-03, np.nan, 6.28930818e-03, np.nan, np.nan, np.nan, 8.23852417e-04, \n",
    "          np.nan, 4.13746771e-03, 5.78127295e-02, np.nan, 9.06361298e-02, 5.12866891e-01, np.nan, \n",
    "          7.72888383e-01, np.nan, 5.74473847e-02, 1.00791122e-03, np.nan, np.nan, np.nan, np.nan, \n",
    "          5.51408207e-01, 7.13270129e-01, np.nan, np.nan, 2.06043956e-01, np.nan, np.nan, np.nan, \n",
    "          np.nan, 1.03012725e-01, 7.70445042e-01, 6.79152307e-01, np.nan, np.nan, 7.19090642e-02, \n",
    "          np.nan, np.nan, np.nan, np.nan, np.nan, 4.20168067e-03, np.nan, 1.05711606e-02, np.nan, \n",
    "          np.nan, np.nan]\n",
    "\n",
    "# Count NaNs\n",
    "nan_count = np.sum(np.isnan(results_cholecT50_chal))\n",
    "print(\"Number of NaNs:\", nan_count)\n",
    "print(np.nanmean(results_cholecT50_chal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of NaNs: [ 0  1  2  3  6 14 15 16 20 21 24 25 26 27 28 30 32 35 37 38 39 41 42 43\n",
      " 44 45 47 49 50 51 53 56 59 61 64 65 66 67 70 71 73 74 75 76 80 81 83 84\n",
      " 85 86 87 89 91 92 93]\n"
     ]
    }
   ],
   "source": [
    "nan_indices = np.where(np.isnan(results_cholecT50_chal))[0]  # [0] extracts the indices from the tuple\n",
    "\n",
    "print(\"Indices of NaNs:\", nan_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.general.dataset_variables import TripletSegmentationVariables\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def count_triplets(video_files,\n",
    "                   triplet_mapping):\n",
    "    \"\"\"\n",
    "    Counts the frequency of each triplet in a set of CholecT50 videos and identifies missing triplets.\n",
    "    \n",
    "    Args:\n",
    "        video_files (List[str]): List of paths to video JSON annotation files.\n",
    "        triplet_mapping (Dict[int, str]): Dictionary mapping triplet IDs to triplet names.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict[str, int], List[str]]: \n",
    "            - Dictionary with triplet names as keys and their counts as values.\n",
    "            - List of missing triplet names (triplets that do not appear in the dataset).\n",
    "    \"\"\"\n",
    "    triplet_counter = Counter()\n",
    "\n",
    "    # Iterate through each video annotation file\n",
    "    for file_path in video_files:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract annotations from JSON\n",
    "        annotations = data.get(\"annotations\", {})\n",
    "\n",
    "        for frame_id, frame_annotations in annotations.items():\n",
    "            for annotation in frame_annotations:\n",
    "                triplet_id = annotation[0] # First element in list is the triplet ID\n",
    "                if triplet_id != -1:\n",
    "                    triplet_id = str(triplet_id + 1) # move zero to one starting spot. \n",
    "                    if triplet_id in triplet_mapping:\n",
    "                        triplet_name = triplet_mapping[triplet_id]\n",
    "                        triplet_counter[triplet_name] += 1\n",
    "                    else: \n",
    "                        raise ValueError(f'cant find triplet_id {triplet_id} for frame_id {frame_id} ')   \n",
    "\n",
    "    # Identify missing triplets\n",
    "    present_triplets = set(triplet_counter.keys())\n",
    "    all_triplets = set(triplet_mapping.values())\n",
    "    missing_triplets = sorted(all_triplets - present_triplets)\n",
    "\n",
    "    return dict(triplet_counter), missing_triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../my_rendezvous/data/CholecT50/labels\\\\VID92.json', '../../my_rendezvous/data/CholecT50/labels\\\\VID96.json', '../../my_rendezvous/data/CholecT50/labels\\\\VID103.json', '../../my_rendezvous/data/CholecT50/labels\\\\VID110.json', '../../my_rendezvous/data/CholecT50/labels\\\\VID111.json']\n",
      "Triplet Counts: {'grasper,null_verb,null_target': 719, 'grasper,grasp,gallbladder': 2758, 'grasper,retract,gallbladder': 1194, 'hook,null_verb,null_target': 962, 'grasper,grasp,peritoneum': 324, 'hook,dissect,cystic_duct': 884, 'hook,coagulate,blood_vessel': 35, 'hook,dissect,cystic_artery': 240, 'hook,cut,blood_vessel': 13, 'clipper,null_verb,null_target': 37, 'clipper,clip,cystic_duct': 161, 'clipper,clip,cystic_artery': 96, 'scissors,cut,cystic_artery': 44, 'scissors,cut,cystic_duct': 78, 'bipolar,coagulate,blood_vessel': 74, 'bipolar,null_verb,null_target': 57, 'hook,dissect,gallbladder': 2147, 'irrigator,aspirate,fluid': 179, 'grasper,retract,liver': 1218, 'grasper,grasp,specimen_bag': 646, 'grasper,pack,gallbladder': 98, 'bipolar,coagulate,liver': 388, 'irrigator,null_verb,null_target': 67, 'hook,coagulate,liver': 2, 'irrigator,irrigate,liver': 3, 'irrigator,irrigate,abdominal_wall_cavity': 1, 'bipolar,grasp,specimen_bag': 3, 'bipolar,coagulate,abdominal_wall_cavity': 60, 'bipolar,dissect,cystic_artery': 82, 'hook,cut,peritoneum': 92, 'bipolar,dissect,cystic_duct': 37, 'grasper,grasp,liver': 16, 'grasper,grasp,omentum': 6, 'grasper,grasp,gut': 24, 'bipolar,dissect,gallbladder': 5, 'scissors,cut,omentum': 3, 'scissors,null_verb,null_target': 9, 'hook,retract,gallbladder': 4, 'hook,dissect,peritoneum': 54, 'grasper,grasp,cystic_duct': 174, 'clipper,clip,blood_vessel': 14, 'grasper,retract,gut': 13, 'bipolar,coagulate,peritoneum': 12, 'hook,coagulate,cystic_duct': 1, 'grasper,grasp,cystic_pedicle': 1}\n",
      "Missing Triplets: ['bipolar,coagulate,cystic_artery', 'bipolar,coagulate,cystic_duct', 'bipolar,coagulate,cystic_pedicle', 'bipolar,coagulate,cystic_plate', 'bipolar,coagulate,gallbladder', 'bipolar,coagulate,omentum', 'bipolar,dissect,adhesion', 'bipolar,dissect,cystic_plate', 'bipolar,dissect,omentum', 'bipolar,grasp,cystic_plate', 'bipolar,grasp,liver', 'bipolar,retract,cystic_duct', 'bipolar,retract,cystic_pedicle', 'bipolar,retract,gallbladder', 'bipolar,retract,liver', 'bipolar,retract,omentum', 'clipper,clip,cystic_pedicle', 'clipper,clip,cystic_plate', 'grasper,dissect,cystic_plate', 'grasper,dissect,gallbladder', 'grasper,dissect,omentum', 'grasper,grasp,cystic_artery', 'grasper,grasp,cystic_plate', 'grasper,retract,cystic_duct', 'grasper,retract,cystic_pedicle', 'grasper,retract,cystic_plate', 'grasper,retract,omentum', 'grasper,retract,peritoneum', 'hook,coagulate,cystic_artery', 'hook,coagulate,cystic_pedicle', 'hook,coagulate,cystic_plate', 'hook,coagulate,gallbladder', 'hook,coagulate,omentum', 'hook,dissect,blood_vessel', 'hook,dissect,cystic_plate', 'hook,dissect,omentum', 'hook,retract,liver', 'irrigator,dissect,cystic_duct', 'irrigator,dissect,cystic_pedicle', 'irrigator,dissect,cystic_plate', 'irrigator,dissect,gallbladder', 'irrigator,dissect,omentum', 'irrigator,irrigate,cystic_pedicle', 'irrigator,retract,gallbladder', 'irrigator,retract,liver', 'irrigator,retract,omentum', 'scissors,coagulate,omentum', 'scissors,cut,adhesion', 'scissors,cut,blood_vessel', 'scissors,cut,cystic_plate', 'scissors,cut,liver', 'scissors,cut,peritoneum', 'scissors,dissect,cystic_plate', 'scissors,dissect,gallbladder', 'scissors,dissect,omentum']\n"
     ]
    }
   ],
   "source": [
    "# Example Usage:\n",
    "\n",
    "ann_dir = '../../my_rendezvous/data/CholecT50/labels'\n",
    "test_list =  [92, 96, 103, 110, 111]\n",
    "test_list_path = [ join(ann_dir, f'VID{test_vid_id}.json')  for test_vid_id in test_list]\n",
    "triplet_mapping = TripletSegmentationVariables.categories['triplet']\n",
    "\n",
    "print(test_list_path)\n",
    "\n",
    "triplet_counts, missing_triplets = count_triplets(test_list_path, triplet_mapping)\n",
    " \n",
    "print(\"Triplet Counts:\", triplet_counts)\n",
    "print(\"Missing Triplets:\", missing_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do the nans matchup to the missing triplets? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 6, 14, 15, 16, 20, 21, 24, 25, 26, 27, 28, 30, 32, 35, 37, 38, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 56, 59, 61, 64, 65, 66, 67, 70, 71, 73, 74, 75, 76, 80, 81, 83, 84, 85, 86, 87, 89, 91, 92, 93]\n",
      "55\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "missing_triplet_ids = sorted([int(triplet_id)-1 for triplet_id, name in triplet_mapping.items() if name in missing_triplets])\n",
    "print(missing_triplet_ids)\n",
    "print(len(missing_triplet_ids))\n",
    "print(len(triplet_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lists are exactly the same (including order).\n"
     ]
    }
   ],
   "source": [
    "if missing_triplet_ids == nan_indices.tolist():\n",
    "    print(\"The lists are exactly the same (including order).\")\n",
    "else:\n",
    "    print(\"The lists are different.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nans represent the missing ground-truth only. In this example. However that means, somethings that should be zeros are Nans  \n",
    "\n",
    "You should only have NaNs when there is no prediction and no ground_truth. \n",
    "\n",
    "\n",
    "\n",
    "1. When there is 0 ground truth and there are some predictions, these should be zero. \n",
    "2. When there is 0 prediction and there exists ground_truth, this should also be zero\n",
    "\n",
    "lets check these out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all the predictions are being penalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. When there is 0 ground truth and there are some predictions, these should be zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "def count_predicted_triplets(prediction_file: str, \n",
    "                             triplet_mapping: Dict[int, str], \n",
    "                             threshold: float = 0.5) -> Tuple[Dict[str, int], List[str]]:\n",
    "    \"\"\"\n",
    "    Counts the frequency of predicted triplets based on a given threshold.\n",
    "    \n",
    "    Args:\n",
    "        prediction_file (str): Path to the JSON prediction file.\n",
    "        triplet_mapping (Dict[int, str]): Dictionary mapping triplet indices to names.\n",
    "        threshold (float): Threshold to determine if a triplet is predicted.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[Dict[str, int], List[str]]: \n",
    "            - Dictionary with triplet names as keys and their count as values.\n",
    "            - List of missing triplets (triplets that are in the mapping but not predicted).\n",
    "    \"\"\"\n",
    "    triplet_counter = Counter()\n",
    "\n",
    "    # Load predictions from file\n",
    "    with open(prediction_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Iterate over each frame prediction\n",
    "    for frame_id, predictions in data.items():\n",
    "        triplet_scores = predictions[\"triplet\"]\n",
    "\n",
    "        # Identify indices where the threshold is exceeded\n",
    "        predicted_triplet_ids = [str(i+1) for i, score in enumerate(triplet_scores) if float(score) >= threshold]\n",
    "        \n",
    "\n",
    "        # Map indices to triplet names\n",
    "        for triplet_id in predicted_triplet_ids:\n",
    "            if triplet_id in triplet_mapping:\n",
    "                triplet_name = triplet_mapping[triplet_id]\n",
    "                triplet_counter[triplet_name] += 1\n",
    "                \n",
    "                print(f'frame_id {frame_id} - Contains {triplet_name}')\n",
    "            else:\n",
    "                raise ValueError(f\"Triplet ID {triplet_id} not found in mapping.\")\n",
    "\n",
    "    # Identify missing triplets\n",
    "    present_triplets = set(triplet_counter.keys())\n",
    "    all_triplets = set(triplet_mapping.values())\n",
    "    missing_triplets = sorted(all_triplets - present_triplets)\n",
    "\n",
    "    return dict(triplet_counter), missing_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage:\n",
    "prediction_file = \"../../my_rendezvous/results/cholecT50-challenge-old-ivtmetrics/results_rendezvous_l8_cholectcholect50-challenge_k0_batchnorm_lowres.json\"  # Replace with actual file\n",
    "triplet_mapping = TripletSegmentationVariables.categories['triplet']\n",
    "\n",
    "predicted_counts, missing_predicted_triplets = count_predicted_triplets(prediction_file, triplet_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Triplet Counts: {'grasper,grasp,specimen_bag': 588, 'grasper,null_verb,null_target': 638, 'grasper,retract,gallbladder': 3118, 'grasper,retract,omentum': 282, 'grasper,grasp,gallbladder': 126, 'hook,dissect,omentum': 221, 'hook,dissect,gallbladder': 3666, 'hook,dissect,cystic_duct': 152, 'hook,dissect,cystic_plate': 77, 'clipper,null_verb,null_target': 6, 'clipper,clip,cystic_duct': 121, 'scissors,cut,cystic_duct': 47, 'grasper,retract,liver': 1391, 'bipolar,coagulate,liver': 387, 'bipolar,coagulate,cystic_plate': 12, 'bipolar,coagulate,gallbladder': 24, 'grasper,pack,gallbladder': 2, 'bipolar,null_verb,null_target': 13, 'bipolar,dissect,gallbladder': 3, 'bipolar,coagulate,abdominal_wall_cavity': 20, 'grasper,retract,gut': 11, 'hook,null_verb,null_target': 75, 'hook,dissect,cystic_artery': 16, 'bipolar,dissect,cystic_duct': 1, 'clipper,clip,cystic_artery': 28, 'grasper,dissect,gallbladder': 2, 'grasper,retract,cystic_plate': 3, 'irrigator,aspirate,fluid': 7, 'scissors,cut,cystic_artery': 3, 'scissors,dissect,gallbladder': 5, 'scissors,null_verb,null_target': 1, 'grasper,retract,peritoneum': 1, 'hook,coagulate,gallbladder': 1, 'hook,coagulate,liver': 7, 'irrigator,null_verb,null_target': 1}\n",
      "Missing Triplets: ['bipolar,coagulate,blood_vessel', 'bipolar,coagulate,cystic_artery', 'bipolar,coagulate,cystic_duct', 'bipolar,coagulate,cystic_pedicle', 'bipolar,coagulate,omentum', 'bipolar,coagulate,peritoneum', 'bipolar,dissect,adhesion', 'bipolar,dissect,cystic_artery', 'bipolar,dissect,cystic_plate', 'bipolar,dissect,omentum', 'bipolar,grasp,cystic_plate', 'bipolar,grasp,liver', 'bipolar,grasp,specimen_bag', 'bipolar,retract,cystic_duct', 'bipolar,retract,cystic_pedicle', 'bipolar,retract,gallbladder', 'bipolar,retract,liver', 'bipolar,retract,omentum', 'clipper,clip,blood_vessel', 'clipper,clip,cystic_pedicle', 'clipper,clip,cystic_plate', 'grasper,dissect,cystic_plate', 'grasper,dissect,omentum', 'grasper,grasp,cystic_artery', 'grasper,grasp,cystic_duct', 'grasper,grasp,cystic_pedicle', 'grasper,grasp,cystic_plate', 'grasper,grasp,gut', 'grasper,grasp,liver', 'grasper,grasp,omentum', 'grasper,grasp,peritoneum', 'grasper,retract,cystic_duct', 'grasper,retract,cystic_pedicle', 'hook,coagulate,blood_vessel', 'hook,coagulate,cystic_artery', 'hook,coagulate,cystic_duct', 'hook,coagulate,cystic_pedicle', 'hook,coagulate,cystic_plate', 'hook,coagulate,omentum', 'hook,cut,blood_vessel', 'hook,cut,peritoneum', 'hook,dissect,blood_vessel', 'hook,dissect,peritoneum', 'hook,retract,gallbladder', 'hook,retract,liver', 'irrigator,dissect,cystic_duct', 'irrigator,dissect,cystic_pedicle', 'irrigator,dissect,cystic_plate', 'irrigator,dissect,gallbladder', 'irrigator,dissect,omentum', 'irrigator,irrigate,abdominal_wall_cavity', 'irrigator,irrigate,cystic_pedicle', 'irrigator,irrigate,liver', 'irrigator,retract,gallbladder', 'irrigator,retract,liver', 'irrigator,retract,omentum', 'scissors,coagulate,omentum', 'scissors,cut,adhesion', 'scissors,cut,blood_vessel', 'scissors,cut,cystic_plate', 'scissors,cut,liver', 'scissors,cut,omentum', 'scissors,cut,peritoneum', 'scissors,dissect,cystic_plate', 'scissors,dissect,omentum']\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Triplet Counts:\", predicted_counts)\n",
    "print(\"Missing Triplets:\", missing_predicted_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "print(len(missing_predicted_triplets))\n",
    "print(len(predicted_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of NaNs: [ 0  1  2  3  6 14 15 16 20 21 24 25 26 27 28 30 32 35 37 38 39 41 42 43\n",
      " 44 45 47 49 50 51 53 56 59 61 64 65 66 67 70 71 73 74 75 76 80 81 83 84\n",
      " 85 86 87 89 91 92 93]\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "nan_indices = np.where(np.isnan(results_cholecT50_chal))[0]  # [0] extracts the indices from the tuple\n",
    "\n",
    "print(\"Indices of NaNs:\", nan_indices)\n",
    "print(len(nan_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_triplet_ids = sorted([int(triplet_id)-1 for triplet_id, name in triplet_mapping.items() if name in predicted_counts.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_triplet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 16, 20, 21, 27, 28, 51, 59, 61, 75}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_set = set(predicted_triplet_ids)\n",
    "nan_set = set(nan_indices)\n",
    "\n",
    "nans_that_were_predicted = predicted_set & nan_set  # In predicted and nans\n",
    "nans_that_were_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_id 1 grasper,dissect,gallbladder 2\n",
      "nan\n",
      "pred_id 59 hook,dissect,cystic_plate 77\n",
      "nan\n",
      "pred_id 75 scissors,dissect,gallbladder 5\n",
      "nan\n",
      "pred_id 16 grasper,retract,cystic_plate 3\n",
      "nan\n",
      "pred_id 51 hook,coagulate,gallbladder 1\n",
      "nan\n",
      "pred_id 20 grasper,retract,omentum 282\n",
      "nan\n",
      "pred_id 21 grasper,retract,peritoneum 1\n",
      "nan\n",
      "pred_id 27 bipolar,coagulate,cystic_plate 12\n",
      "nan\n",
      "pred_id 28 bipolar,coagulate,gallbladder 24\n",
      "nan\n",
      "pred_id 61 hook,dissect,omentum 221\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "for pred_id in nans_that_were_predicted:\n",
    "    pred_name = triplet_mapping[str(pred_id+1)]\n",
    "    print(f'pred_id {pred_id} {pred_name} {predicted_counts[pred_name]}')\n",
    "    print(results_cholecT50_chal[pred_id]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 classes which have predictions but no ground truth and it is reported as NaN which is wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. When there is 0 prediction and there exists ground_truth, this should also be zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for this one, we need to check all the places that have missing predictions and see if it aligns with ground_truth that exists. It should give zero\n",
    "\n",
    "There are 35 predictions but there 45 ground_truths, hence there must at least be 10 that have zero in ivt but looking at it, there are no zeros, something is wrong here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results_cholecT50_chal) == 0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is none that is zero so something is fishy here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_set = set(predicted_triplet_ids)\n",
    "\n",
    "gt_triplet_ids = sorted([int(triplet_id)-1 for triplet_id, name in triplet_mapping.items() if name in triplet_counts.keys()])\n",
    "gt_set = set(gt_triplet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences found!\n",
      "Extra elements in predicted indices: {1, 59, 75, 16, 51, 20, 21, 27, 28, 61}\n",
      "Extra elements in gt_indices: {4, 5, 8, 9, 10, 11, 23, 31, 33, 40, 46, 48, 54, 55, 62, 63, 72, 77, 88, 90}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "extra_in_predicted = predicted_set - gt_set  #if there is even any extra\n",
    "extra_in_gt = gt_set - predicted_set  # I expect at least ten, it could be more. \n",
    "\n",
    "if not extra_in_predicted and not extra_in_gt:\n",
    "    print(\"The lists contain the same elements.\")\n",
    "else:\n",
    "    print(\"Differences found!\")\n",
    "    if extra_in_predicted:\n",
    "        print(\"Extra elements in predicted indices:\", extra_in_predicted)\n",
    "    if extra_in_gt:\n",
    "        print(\"Extra elements in gt_indices:\", extra_in_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 59, 75, 16, 51, 20, 21, 27, 28, 61}\n",
      "{1, 59, 75, 16, 51, 20, 21, 27, 28, 61}\n"
     ]
    }
   ],
   "source": [
    "print(extra_in_predicted)\n",
    "print(nans_that_were_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That makes sense, these things that we have predictions for , but no groundtruth, they were teh nans that have predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This then implies that there are another 20 which should have been zeros that were not zeros. They are the groundtruths that have no predictions, but somehow are not scored as zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gt_id_that_should_be_zero in extra_in_gt:\n",
    "    gt_name = triplet_mapping[str(gt_id_that_should_be_zero+1)]\n",
    "    print(f'gt_id_that_should_be_zero {gt_id_that_should_be_zero} {gt_name}')\n",
    "    print(f'frequency in gt {triplet_counts[gt_name]}')\n",
    "    print(f'frequency in pred {predicted_counts.get(gt_name, 0)}')\n",
    "    print(f'is it in missing from pred {gt_name in missing_predicted_triplets}')\n",
    "    print('result on old ivtmetrics' , results_cholecT50_chal[gt_id_that_should_be_zero]) \n",
    "    print('=================================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are essentially passing the whole triplet vector in, so they are not doing what we are doing, but they are passing all the triplet classes in!!! That is why we have predictions even when things are missing. \n",
    "\n",
    "But there should be a threshold, there should be a threshold, even when working with logits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to answer? \n",
    "\n",
    "Why does the new version not have any NaN at all? Their method for catching when it is NaN is wrong, likely the output from sklearn is no longer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP Score using probabilities: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Example true labels\n",
    "y_true = [0, 0, 1, 1]\n",
    "\n",
    "\n",
    "# Probabilities (e.g., logistic regression)\n",
    "y_scores_proba = [0.1, 0.2, 0.3, 0.9]  # Probabilities of class 1\n",
    "\n",
    "# Compute Average Precision Score\n",
    "ap_proba = average_precision_score(y_true, y_scores_proba)\n",
    "\n",
    "print(\"AP Score using probabilities:\", ap_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not use threshold of 0.5, that is why I am making mistakes\n",
    "\n",
    "So my whole analysis is wrong. \n",
    "\n",
    "As classification AP is not the same as Detection AP, very different in their calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My analysis is very wrong and i realize I have being looking at things from the view of object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same analysis is required in the detection one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under detection rules, what would be the triplet score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cholecT50_chal_copy = results_cholecT50_chal[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([           nan,            nan,            nan,            nan,\n",
       "       1.42380420e-01, 5.12557663e-04,            nan, 3.32626728e-01,\n",
       "       1.94041245e-02, 4.41499286e-03, 1.51810978e-02, 1.05866348e-01,\n",
       "       7.66676512e-01, 3.34643930e-01,            nan,            nan,\n",
       "                  nan, 3.49844877e-01, 2.36705437e-01, 6.40751279e-01,\n",
       "                  nan,            nan, 6.16255123e-01, 3.82526038e-01,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan, 9.38378809e-01,            nan, 6.81760326e-01,\n",
       "                  nan, 2.39063315e-01, 6.76337083e-01,            nan,\n",
       "       1.46892996e-01,            nan,            nan,            nan,\n",
       "       2.24427652e-02,            nan,            nan,            nan,\n",
       "                  nan,            nan, 5.29207639e-03,            nan,\n",
       "       6.28930818e-03,            nan,            nan,            nan,\n",
       "       8.23852417e-04,            nan, 4.13746771e-03, 5.78127295e-02,\n",
       "                  nan, 9.06361298e-02, 5.12866891e-01,            nan,\n",
       "       7.72888383e-01,            nan, 5.74473847e-02, 1.00791122e-03,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "       5.51408207e-01, 7.13270129e-01,            nan,            nan,\n",
       "       2.06043956e-01,            nan,            nan,            nan,\n",
       "                  nan, 1.03012725e-01, 7.70445042e-01, 6.79152307e-01,\n",
       "                  nan,            nan, 7.19090642e-02,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "       4.20168067e-03,            nan, 1.05711606e-02,            nan,\n",
       "                  nan,            nan])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cholecT50_chal_copy = np.array(results_cholecT50_chal_copy)\n",
    "results_cholecT50_chal_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra_in_predicted refer to the ground_truths that do not exist but have predictions, the score should be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([           nan, 0.00000000e+00,            nan,            nan,\n",
       "       1.42380420e-01, 5.12557663e-04,            nan, 3.32626728e-01,\n",
       "       1.94041245e-02, 4.41499286e-03, 1.51810978e-02, 1.05866348e-01,\n",
       "       7.66676512e-01, 3.34643930e-01,            nan,            nan,\n",
       "       0.00000000e+00, 3.49844877e-01, 2.36705437e-01, 6.40751279e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.16255123e-01, 3.82526038e-01,\n",
       "                  nan,            nan,            nan, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.38378809e-01,            nan, 6.81760326e-01,\n",
       "                  nan, 2.39063315e-01, 6.76337083e-01,            nan,\n",
       "       1.46892996e-01,            nan,            nan,            nan,\n",
       "       2.24427652e-02,            nan,            nan,            nan,\n",
       "                  nan,            nan, 5.29207639e-03,            nan,\n",
       "       6.28930818e-03,            nan,            nan, 0.00000000e+00,\n",
       "       8.23852417e-04,            nan, 4.13746771e-03, 5.78127295e-02,\n",
       "                  nan, 9.06361298e-02, 5.12866891e-01, 0.00000000e+00,\n",
       "       7.72888383e-01, 0.00000000e+00, 5.74473847e-02, 1.00791122e-03,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "       5.51408207e-01, 7.13270129e-01,            nan,            nan,\n",
       "       2.06043956e-01,            nan,            nan, 0.00000000e+00,\n",
       "                  nan, 1.03012725e-01, 7.70445042e-01, 6.79152307e-01,\n",
       "                  nan,            nan, 7.19090642e-02,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "       4.20168067e-03,            nan, 1.05711606e-02,            nan,\n",
       "                  nan,            nan])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cholecT50_chal_copy[list(extra_in_predicted)] = 0\n",
    "results_cholecT50_chal_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra in gt refers to pred that do not exist but there are groudtruths present, all missing false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([           nan, 0.00000000e+00,            nan,            nan,\n",
       "       0.00000000e+00, 0.00000000e+00,            nan, 3.32626728e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.66676512e-01, 3.34643930e-01,            nan,            nan,\n",
       "       0.00000000e+00, 3.49844877e-01, 2.36705437e-01, 6.40751279e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.16255123e-01, 0.00000000e+00,\n",
       "                  nan,            nan,            nan, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.38378809e-01,            nan, 0.00000000e+00,\n",
       "                  nan, 0.00000000e+00, 6.76337083e-01,            nan,\n",
       "       1.46892996e-01,            nan,            nan,            nan,\n",
       "       0.00000000e+00,            nan,            nan,            nan,\n",
       "                  nan,            nan, 0.00000000e+00,            nan,\n",
       "       0.00000000e+00,            nan,            nan, 0.00000000e+00,\n",
       "       8.23852417e-04,            nan, 0.00000000e+00, 0.00000000e+00,\n",
       "                  nan, 9.06361298e-02, 5.12866891e-01, 0.00000000e+00,\n",
       "       7.72888383e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "       5.51408207e-01, 7.13270129e-01,            nan,            nan,\n",
       "       0.00000000e+00,            nan,            nan, 0.00000000e+00,\n",
       "                  nan, 0.00000000e+00, 7.70445042e-01, 6.79152307e-01,\n",
       "                  nan,            nan, 7.19090642e-02,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "       0.00000000e+00,            nan, 0.00000000e+00,            nan,\n",
       "                  nan,            nan])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cholecT50_chal_copy[list(extra_in_gt)] = 0\n",
    "results_cholecT50_chal_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18780638325340818"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(results_cholecT50_chal_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well this is not actually correct as well, the values of the AP the plotting is different. But it is getting closer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".evaluate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
